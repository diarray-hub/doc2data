{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f43f5c1b",
   "metadata": {},
   "source": [
    "## Make sure you set your API key\n",
    "\n",
    "The Landing.AI system is proprietary, so you need an api key to use the python library. Make sure you exported a key, you can obtain one on [the visual playground page](https://va.landing.ai/my/settings/api-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export VISION_AGENT_API_KEY=<your-api-key>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef53808",
   "metadata": {},
   "source": [
    "## Parse File\n",
    "\n",
    "In this introductory notebook, we will only explore the Parse and Extract API function. That's all we need for this demo, but you can also [clasify or separate a large document into subdocuments](https://docs.landing.ai/ade/ade-python#split:-getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from landingai_ade import LandingAIADE\n",
    "\n",
    "client = LandingAIADE()\n",
    "\n",
    "# Replace with your file path\n",
    "response = client.parse(p\n",
    "    document=Path(\"/path/to/file/document\"), # clone this repo and access ./test-docs/example-fr.png\n",
    "    model=\"dpt-2-latest\"\n",
    ")\n",
    "print(response.chunks)\n",
    "\n",
    "# Save Markdown output (useful if you plan to run extract on the Markdown)\n",
    "with open(\"output.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.markdown)\n",
    "    \n",
    "# If you take a look at the parsed document you'll see that the table was handled very well \n",
    "# and even information that are hard to read like the FasoTax percentages are clearly extractable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3d3b6",
   "metadata": {},
   "source": [
    "With the example code above you can also parse online documents, for that you just need to use the document_url= parameter (eg.  document_url=\"https://example.com/document.pdf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67470ee",
   "metadata": {},
   "source": [
    "## Information Extraction\n",
    "\n",
    "You can call the extract function with the markdown string returned by the parse function or pass the path or url of an already pasted document.\n",
    "\n",
    "```\n",
    "# Parse the document\n",
    "parse_response = client.parse(\n",
    "    document=Path(\"/path/to/document.pdf\"),\n",
    "    model=\"dpt-2-latest\"\n",
    ")\n",
    "\n",
    "# Extract data using the markdown string from parse response\n",
    "extract_response = client.extract(\n",
    "    schema=schema_json,\n",
    "    markdown=parse_response.markdown,  # Pass markdown string directly\n",
    "    model=\"extract-latest\"\n",
    ")\n",
    "\n",
    "# Or Extract from a local markdown file\n",
    "extract_response = client.extract(\n",
    "    schema=schema_json,\n",
    "    markdown=Path(\"/path/to/output.md\"),\n",
    "    model=\"extract-latest\"\n",
    ")\n",
    "\n",
    "# Or extract from a remote markdown file\n",
    "extract_response = client.extract(\n",
    "    schema=schema_json,\n",
    "    markdown_url=\"https://example.com/document.md\",\n",
    "    model=\"extract-latest\"\n",
    ")\n",
    "```\n",
    "\n",
    "But the most important part of the extraction workflow is to define a schema that accurately describe the information you want to extract from your document. This is, sort of the prompt engineering part of the thing, even if the system performs very at extracted visible/labeled information with detailed descriptions, in general the more detailed your descriptions are the better it is for the extraction of the information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d87a88",
   "metadata": {},
   "source": [
    "Schemas passed to the API are in JSON format, but I recommend using Pydantic models to define your extraction schema to enhance it with type information and structured descriptions, so that the extracted information is type-aware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f68328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "from landingai_ade import LandingAIADE\n",
    "from landingai_ade.lib import pydantic_to_json_schema\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CommercialContact(BaseModel):\n",
    "    name: str = Field(\n",
    "        ...,\n",
    "        description='The name of the commercial contact person.',\n",
    "        title='Contact Name',\n",
    "    )\n",
    "    phone_number: str = Field(\n",
    "        ...,\n",
    "        description='The phone number of the commercial contact.',\n",
    "        title='Phone Number',\n",
    "    )\n",
    "class PricingPlan(BaseModel):\n",
    "    plan_name: str = Field(\n",
    "        ...,\n",
    "        description='The name of the fiber optic plan (e.g., ESSENTIEL, CONFORT, PREMIUM).',\n",
    "        title='Plan Name',\n",
    "    )\n",
    "    speed: str = Field(\n",
    "        ...,\n",
    "        description='The advertised internet speed for the plan in Mb/s.',\n",
    "        title='Internet Speed',\n",
    "    )\n",
    "# With this  schema we wanna extract the language of the document (inferred by the agent)\n",
    "# the contact of the commercial person for subscriptions\n",
    "# the pricing plans details for different fiber optic offers\n",
    "# and the total price for a 6-month prepaid \"Confort\" plan including FMS, subscription, and FasoTax\n",
    "class FiberOpticServiceInformation(BaseModel):\n",
    "    language: str = Field(\n",
    "        ...,\n",
    "        description='The inferred language of the document.',\n",
    "        title='Document Language',\n",
    "    )\n",
    "    commercial_contact: CommercialContact = Field(\n",
    "        ...,\n",
    "        description='Details of the commercial contact person for subscriptions.',\n",
    "        title='Commercial Contact Information',\n",
    "    )\n",
    "    offers_summary: str = Field(\n",
    "        ...,\n",
    "        description='A brief summary of the main offers mentioned at the beginning of the document.',\n",
    "        title='Initial Offers Summary',\n",
    "    )\n",
    "    pricing_plans: List[PricingPlan] = Field(\n",
    "        ...,\n",
    "        description='An array of detailed pricing plans for different fiber optic offers.',\n",
    "        title='Detailed Pricing Plans',\n",
    "    )\n",
    "    confort_6_month_total_price: int = Field(\n",
    "        ...,\n",
    "        description=\"The total price for a 6-month prepaid 'Confort' plan, including FMS, subscription, and FasoTax.\",\n",
    "        title='Confort 6-Month Prepaid Total Price',\n",
    "    )\n",
    "\n",
    "# Extract structured data using the schema\n",
    "extract_response = client.extract(\n",
    "    schema=schema,\n",
    "    markdown=Path(\"/path/to/output.md\"),\n",
    ")\n",
    "\n",
    "print(extract_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75140e0e",
   "metadata": {},
   "source": [
    "See the Pydantic model defintion as if you were defining a class and its attribute while designing a database, you can symbolized complex class relationships with nested structures (see [Nested subfields in the docs](https://docs.landing.ai/ade/ade-python#extract-nested-subfields)). You can also [Extract Variable-Length Data with List Objects](https://docs.landing.ai/ade/ade-python#extract-variable-length-data-with-list-objects).\n",
    "You can also use pre-created schemas saved to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83574a",
   "metadata": {},
   "source": [
    "## Linking Extracted Data to Document Locations\n",
    "\n",
    "Use the reference IDs from extraction_metadata to find the exact location where data was extracted in the source document. This is useful for visual validation, quality assurance, or building confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link extracted field to its source location\n",
    "chunk_id = extract_response.extraction_metadata[\"commercial_contact\"][\"name\"][\"references\"][0]\n",
    "\n",
    "print(f\"Commercial name (chunk_id {chunk_id}): {extract_response.extraction['commercial_contact']['name']}\")\n",
    "\n",
    "phone = extract_response.extraction['commercial_contact']['phone_number']\n",
    "print(f\"Commercial phone number: {phone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4fa5b",
   "metadata": {},
   "source": [
    "You can use [va.landing.ai](https://va.landing.ai/) to have an LLM generate your pydantic schemas (that's one functionality that we will implement for our demo app).\n",
    "I also recommend checking thier [documentation](https://docs.landing.ai/) for further information and API documentation, it is a great AI augmented doc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8f74e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
